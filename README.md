# ğŸš€ Crypto Analytics Platform - Medallion Architecture

## ğŸ“Š Project Overview

A production-grade cryptocurrency analytics platform implementing the **Medallion Architecture** (Bronze â†’ Silver â†’ Gold) with orchestrated data pipelines, ML-based price prediction, and interactive visualizations.

### Business Goals
1. **Real-time Crypto Monitoring**: Track Bitcoin, Ethereum, and altcoins with live price data
2. **Portfolio Optimization**: Calculate optimal portfolio weights using Sharpe Ratio maximization
3. **Price Prediction**: ML models to forecast cryptocurrency prices
4. **Risk Analysis**: Volatility tracking, correlation analysis, and technical indicators
5. **Automated Reporting**: Daily dashboards with actionable insights

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DATA SOURCES                             â”‚
â”‚  â€¢ Yahoo Finance API  â€¢ CoinGecko API  â€¢ Binance API            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ORCHESTRATION LAYER                           â”‚
â”‚                    Apache Airflow (DAGs)                         â”‚
â”‚  â€¢ Ingestion DAG  â€¢ Transformation DAG  â€¢ ML Training DAG       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MEDALLION ARCHITECTURE                        â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚    BRONZE    â”‚â”€â”€â”€â–¶â”‚    SILVER    â”‚â”€â”€â”€â–¶â”‚     GOLD     â”‚     â”‚
â”‚  â”‚  Raw Data    â”‚    â”‚  Cleaned &   â”‚    â”‚  Business    â”‚     â”‚
â”‚  â”‚  Lake        â”‚    â”‚  Validated   â”‚    â”‚  Aggregates  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                  â”‚
â”‚  Storage: PostgreSQL / DuckDB / Delta Lake                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   TRANSFORMATION LAYER (dbt)                     â”‚
â”‚  â€¢ Data Quality Tests  â€¢ Feature Engineering  â€¢ Aggregations   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ML PIPELINE                                 â”‚
â”‚  â€¢ LSTM/Prophet Models  â€¢ Sharpe Ratio Optimizer               â”‚
â”‚  â€¢ Technical Indicators  â€¢ Model Registry (MLflow)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       BI LAYER                                   â”‚
â”‚  â€¢ Streamlit Dashboard  â€¢ Plotly/Dash  â€¢ Metabase              â”‚
â”‚  â€¢ Real-time Monitoring  â€¢ Alerts & Notifications              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ Project Structure

```
crypto-analytics-platform/
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ docker-compose.yml          # All services orchestration
â”‚   â”œâ”€â”€ airflow.Dockerfile
â”‚   â”œâ”€â”€ dbt.Dockerfile
â”‚   â””â”€â”€ streamlit.Dockerfile
â”‚
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â”œâ”€â”€ bronze_ingestion_dag.py      # Raw data ingestion (15min intervals)
â”‚   â”‚   â”œâ”€â”€ silver_transformation_dag.py  # Data cleaning & validation
â”‚   â”‚   â”œâ”€â”€ gold_aggregation_dag.py      # Business metrics
â”‚   â”‚   â”œâ”€â”€ ml_training_dag.py           # Model training & prediction
â”‚   â”‚   â””â”€â”€ portfolio_optimization_dag.py # Sharpe ratio calculation
â”‚   â”œâ”€â”€ plugins/
â”‚   â”‚   â”œâ”€â”€ operators/
â”‚   â”‚   â”‚   â”œâ”€â”€ crypto_api_operator.py
â”‚   â”‚   â”‚   â””â”€â”€ model_training_operator.py
â”‚   â”‚   â””â”€â”€ sensors/
â”‚   â”‚       â””â”€â”€ data_quality_sensor.py
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ connections.json
â”‚
â”œâ”€â”€ dbt/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ bronze/
â”‚   â”‚   â”‚   â”œâ”€â”€ bronze_btc_raw.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ bronze_eth_raw.sql
â”‚   â”‚   â”‚   â””â”€â”€ schema.yml
â”‚   â”‚   â”œâ”€â”€ silver/
â”‚   â”‚   â”‚   â”œâ”€â”€ silver_crypto_cleaned.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ silver_technical_indicators.sql   # SMA, EMA, Bollinger
â”‚   â”‚   â”‚   â”œâ”€â”€ silver_returns.sql                # Log returns, volatility
â”‚   â”‚   â”‚   â””â”€â”€ schema.yml
â”‚   â”‚   â””â”€â”€ gold/
â”‚   â”‚       â”œâ”€â”€ gold_crypto_metrics.sql           # Daily aggregates
â”‚   â”‚       â”œâ”€â”€ gold_portfolio_weights.sql        # Optimized weights
â”‚   â”‚       â”œâ”€â”€ gold_correlation_matrix.sql
â”‚   â”‚       â”œâ”€â”€ gold_price_predictions.sql
â”‚   â”‚       â””â”€â”€ schema.yml
â”‚   â”œâ”€â”€ macros/
â”‚   â”‚   â”œâ”€â”€ calculate_returns.sql
â”‚   â”‚   â”œâ”€â”€ bollinger_bands.sql
â”‚   â”‚   â””â”€â”€ technical_indicators.sql
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â””â”€â”€ data_quality_tests.sql
â”‚   â””â”€â”€ dbt_project.yml
â”‚
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ price_prediction/
â”‚   â”‚   â”‚   â”œâ”€â”€ lstm_model.py
â”‚   â”‚   â”‚   â”œâ”€â”€ prophet_model.py
â”‚   â”‚   â”‚   â””â”€â”€ ensemble_model.py
â”‚   â”‚   â”œâ”€â”€ portfolio_optimization/
â”‚   â”‚   â”‚   â”œâ”€â”€ sharpe_optimizer.py
â”‚   â”‚   â”‚   â””â”€â”€ monte_carlo.py
â”‚   â”‚   â””â”€â”€ feature_engineering/
â”‚   â”‚       â””â”€â”€ technical_features.py
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ train_pipeline.py
â”‚   â”œâ”€â”€ inference/
â”‚   â”‚   â””â”€â”€ predict_pipeline.py
â”‚   â””â”€â”€ mlflow/
â”‚       â””â”€â”€ mlruns/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ yahoo_finance_client.py
â”‚   â”‚   â”œâ”€â”€ coingecko_client.py
â”‚   â”‚   â””â”€â”€ binance_client.py
â”‚   â”œâ”€â”€ transformation/
â”‚   â”‚   â”œâ”€â”€ data_cleaner.py
â”‚   â”‚   â””â”€â”€ validators.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ config.py
â”‚       â”œâ”€â”€ logger.py
â”‚       â””â”€â”€ database.py
â”‚
â”œâ”€â”€ streamlit/
â”‚   â”œâ”€â”€ app.py                      # Main dashboard
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ 1_ğŸ“ˆ_Live_Prices.py
â”‚   â”‚   â”œâ”€â”€ 2_ğŸ’¼_Portfolio_Optimizer.py
â”‚   â”‚   â”œâ”€â”€ 3_ğŸ”®_Price_Predictions.py
â”‚   â”‚   â”œâ”€â”€ 4_ğŸ“Š_Technical_Analysis.py
â”‚   â”‚   â””â”€â”€ 5_ğŸ”—_Correlation_Matrix.py
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ charts.py
â”‚   â”‚   â””â”€â”€ metrics.py
â”‚   â””â”€â”€ config.toml
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ data_quality/
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml
â”‚   â”œâ”€â”€ db_schema.sql
â”‚   â””â”€â”€ secrets.env.example
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup_db.sh
â”‚   â”œâ”€â”€ init_airflow.sh
â”‚   â””â”€â”€ seed_historical_data.py
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ exploratory/
â”‚   â”‚   â”œâ”€â”€ Bitcoin_Analysis.ipynb       # Your original analysis
â”‚   â”‚   â”œâ”€â”€ Sharpe_Ratio_Research.ipynb
â”‚   â”‚   â””â”€â”€ Correlation_Study.ipynb
â”‚   â””â”€â”€ experiments/
â”‚       â””â”€â”€ model_experiments.ipynb
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml
â”‚       â””â”€â”€ deploy.yml
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Makefile
â””â”€â”€ README.md
```

---

## ğŸ¯ Medallion Architecture Deep Dive

### ğŸ¥‰ Bronze Layer (Raw Data Lake)
**Purpose**: Store raw, immutable data exactly as received from sources

**Data Sources**:
- Yahoo Finance API (yfinance)
- CoinGecko API (real-time prices, market cap)
- Binance API (order book, trading volume)

**Tables**:
```sql
bronze.raw_crypto_prices
  - timestamp, symbol, open, high, low, close, volume, source_api
  
bronze.raw_market_data
  - timestamp, symbol, market_cap, circulating_supply, total_volume

bronze.raw_orderbook
  - timestamp, symbol, bids, asks, spread
```

**Ingestion Frequency**:
- Real-time: Every 1 minute (WebSocket for critical coins)
- Batch: Every 15 minutes (REST API for all coins)
- Historical: Daily backfill

---

### ğŸ¥ˆ Silver Layer (Cleaned & Validated)
**Purpose**: Cleaned, deduplicated, validated data with business logic applied

**dbt Models**:
```sql
silver.crypto_prices_cleaned
  - Removes duplicates, handles missing values
  - Type validation, outlier detection
  - Adds calculated fields: log_return, price_change_pct

silver.technical_indicators
  - SMA (20, 50, 200 day)
  - EMA (12, 26 day)
  - RSI, MACD, Bollinger Bands
  - Volatility metrics

silver.returns_and_risk
  - Daily returns
  - Rolling volatility (30, 60, 90 day)
  - Cumulative returns
  - Drawdown analysis
```

**Data Quality Tests** (dbt tests):
- Not null checks on critical columns
- Accepted value ranges (price > 0)
- Freshness checks (data < 1 hour old)
- Relationship integrity

---

### ğŸ¥‡ Gold Layer (Business Metrics)
**Purpose**: Aggregated, business-ready data for analytics and ML

**Tables**:
```sql
gold.daily_crypto_metrics
  - Daily OHLCV aggregates
  - Volume-weighted average price
  - Daily returns, volatility
  
gold.portfolio_weights_optimized
  - Optimal allocation weights (Sharpe ratio maximization)
  - Risk metrics, expected returns
  - Rebalancing recommendations

gold.price_predictions
  - Next-day, 7-day, 30-day forecasts
  - Confidence intervals
  - Model metadata (accuracy, MAE, RMSE)

gold.correlation_matrix
  - Pairwise crypto correlations
  - Rolling correlation windows
  - Network analysis metrics
```

---

## ğŸŒŠ Airflow DAGs

### 1. **Bronze Ingestion DAG** (`bronze_ingestion_dag.py`)
```python
Schedule: */15 * * * *  (Every 15 minutes)

Tasks:
  1. fetch_yahoo_finance_data
  2. fetch_coingecko_data
  3. validate_api_response
  4. write_to_bronze_layer
  5. data_quality_check
  6. trigger_silver_dag
```

### 2. **Silver Transformation DAG** (`silver_transformation_dag.py`)
```python
Schedule: Triggered by Bronze DAG

Tasks:
  1. dbt_run_silver_models
  2. calculate_technical_indicators
  3. compute_returns_volatility
  4. run_dbt_tests
  5. trigger_gold_dag
```

### 3. **Gold Aggregation DAG** (`gold_aggregation_dag.py`)
```python
Schedule: Triggered by Silver DAG

Tasks:
  1. dbt_run_gold_models
  2. calculate_daily_metrics
  3. update_correlation_matrix
  4. generate_portfolio_weights
  5. refresh_dashboard_cache
```

### 4. **ML Training DAG** (`ml_training_dag.py`)
```python
Schedule: 0 2 * * *  (Daily at 2 AM)

Tasks:
  1. prepare_training_data
  2. train_lstm_model
  3. train_prophet_model
  4. evaluate_models
  5. register_best_model_mlflow
  6. generate_predictions
```

### 5. **Portfolio Optimization DAG** (`portfolio_optimization_dag.py`)
```python
Schedule: 0 0 * * MON  (Weekly on Monday)

Tasks:
  1. fetch_historical_returns
  2. calculate_covariance_matrix
  3. run_monte_carlo_simulation
  4. optimize_sharpe_ratio
  5. generate_rebalancing_report
  6. send_email_notification
```

---

## ğŸ¨ BI Layer & Visualization Options

### Option 1: **Streamlit** (Recommended for Rapid Development)
âœ… **Pros**: 
- Python-native, easy integration with pandas/plotly
- Real-time updates, custom ML model integration
- Fast prototyping, great for data scientists

**Dashboard Structure**:
```python
# Main App: Real-time Crypto Monitor
streamlit/app.py
  - Live price tickers
  - Interactive candlestick charts (Plotly)
  - Portfolio value tracking
  - Alert notifications

# Page 1: Portfolio Optimizer
  - Monte Carlo simulation visualization
  - Efficient frontier plot
  - Sharpe ratio maximization results
  - Rebalancing recommendations

# Page 2: Price Predictions
  - LSTM vs Prophet comparison
  - Confidence interval bands
  - Model performance metrics
  - Feature importance charts

# Page 3: Technical Analysis
  - Bollinger Bands overlay
  - RSI & MACD indicators
  - Volume analysis
  - Support/resistance levels

# Page 4: Correlation Heatmap
  - Interactive correlation matrix
  - Network graph visualization
  - Time-series correlation trends
```

### Option 2: **Plotly Dash** (Interactive Web Apps)
âœ… **Pros**:
- More control over layout and callbacks
- Better for complex interactions
- Production-ready with Dash Enterprise

### Option 3: **Metabase** (Self-Service BI)
âœ… **Pros**:
- No-code dashboard builder
- Great for business users
- SQL-based, connects to PostgreSQL

### Option 4: **Apache Superset** (Open-Source BI)
âœ… **Pros**:
- Enterprise-grade dashboards
- Advanced filtering and drill-downs
- SQL Lab for ad-hoc queries

### Option 5: **Grafana** (Real-Time Monitoring)
âœ… **Pros**:
- Best for time-series data
- Alerting and notifications
- Great for ops monitoring

---

## ğŸ§° Technology Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Orchestration** | Apache Airflow | DAG scheduling, workflow management |
| **Data Transformation** | dbt (Data Build Tool) | SQL transformations, testing, documentation |
| **Database** | PostgreSQL / DuckDB | OLTP + OLAP workloads |
| **Data Lake** | MinIO / S3 | Raw data storage (optional) |
| **ML Framework** | TensorFlow/PyTorch, Prophet | Price prediction models |
| **ML Ops** | MLflow | Model registry, experiment tracking |
| **API Clients** | yfinance, ccxt, requests | Data ingestion |
| **BI/Viz** | Streamlit + Plotly | Interactive dashboards |
| **Containerization** | Docker + Docker Compose | Environment consistency |
| **CI/CD** | GitHub Actions | Automated testing & deployment |
| **Monitoring** | Prometheus + Grafana (optional) | System health monitoring |

---

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- Python 3.10+
- PostgreSQL 14+ (or use Docker)

### 1. Clone & Setup
```bash
git clone https://github.com/yourusername/crypto-analytics-platform.git
cd crypto-analytics-platform

# Copy environment variables
cp config/secrets.env.example config/secrets.env
# Edit secrets.env with your API keys

# Build Docker containers
docker-compose build

# Initialize Airflow database
docker-compose run airflow-init

# Start all services
docker-compose up -d
```

### 2. Access Services
- **Airflow UI**: http://localhost:8080 (user: admin, pass: admin)
- **Streamlit Dashboard**: http://localhost:8501
- **MLflow UI**: http://localhost:5000
- **PostgreSQL**: localhost:5432

### 3. Seed Historical Data
```bash
docker-compose exec airflow python /scripts/seed_historical_data.py
```

### 4. Trigger Initial DAGs
```bash
# Via Airflow UI or CLI
docker-compose exec airflow airflow dags trigger bronze_ingestion_dag
```

---

## ğŸ“Š Key Features

### 1. Real-Time Price Tracking
- Live Bitcoin, Ethereum, and top 20 altcoins
- 15-minute candlestick charts
- Volume-weighted average price (VWAP)

### 2. Portfolio Optimization
- Monte Carlo simulation (10,000+ iterations)
- Sharpe Ratio maximization
- Risk-adjusted return calculations
- Weekly rebalancing recommendations

### 3. Price Prediction Models
- **LSTM Neural Network**: Deep learning for time-series
- **Facebook Prophet**: Trend + seasonality decomposition
- **Ensemble Model**: Combines multiple predictions
- Rolling 7-day, 30-day forecasts

### 4. Technical Analysis
- **Indicators**: SMA, EMA, RSI, MACD, Bollinger Bands
- **Volatility**: Historical volatility, GARCH models
- **Support/Resistance**: Automatic level detection

### 5. Correlation Analysis
- Crypto correlation matrix (BTC, ETH, XRP, ADA, DOGE, BNB, DASH)
- Rolling correlation windows
- Portfolio diversification insights

### 6. Automated Alerts
- Price threshold notifications
- Volatility spike alerts
- Portfolio rebalancing triggers
- Model drift detection

---

## ğŸ§ª Data Quality & Testing

### dbt Tests
```yaml
# models/silver/schema.yml
models:
  - name: silver_crypto_prices_cleaned
    tests:
      - dbt_utils.recency:
          field: timestamp
          interval: 1
          interval_unit: hour
    columns:
      - name: close_price
        tests:
          - not_null
          - positive_value
```

### Custom Data Quality Checks
```python
# airflow/plugins/sensors/data_quality_sensor.py
class DataQualitySensor(BaseSensorOperator):
    def poke(self, context):
        # Check for missing data
        # Validate price ranges
        # Ensure no duplicates
        return quality_passed
```

---

## ğŸ“ˆ Performance Optimization

1. **Incremental dbt Models**: Only process new data
2. **Airflow Task Parallelization**: Fetch multiple coins simultaneously
3. **Database Indexing**: Optimize queries on timestamp + symbol
4. **Caching**: Redis for dashboard data (5-minute TTL)
5. **Batch Predictions**: Pre-compute forecasts, serve from cache

---

## ğŸ”’ Security Best Practices

- API keys stored in environment variables (never committed)
- Database credentials in Docker secrets
- Airflow connections encrypted
- HTTPS for production deployments
- Rate limiting on API calls

---

## ğŸ“š Documentation

- **API Documentation**: Automatically generated with dbt docs
- **Airflow DAG Documentation**: Docstrings in each DAG file
- **Model Cards**: ML model metadata in MLflow
- **Architecture Diagrams**: `/docs/architecture/`

---

## ğŸ›£ï¸ Roadmap

### Phase 1 (Current)
- âœ… Basic price ingestion
- âœ… Technical indicator calculation
- âœ… Sharpe ratio optimization

### Phase 2 (Next 2 months)
- ğŸ”² Real-time WebSocket ingestion
- ğŸ”² Advanced ML models (LSTM, Transformer)
- ğŸ”² Automated backtesting framework
- ğŸ”² Sentiment analysis from Twitter/Reddit

### Phase 3 (Future)
- ğŸ”² Multi-exchange arbitrage detection
- ğŸ”² On-chain analytics integration
- ğŸ”² Reinforcement learning trading agents
- ğŸ”² Mobile app with push notifications

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

MIT License - see LICENSE file for details

---

## ğŸ“§ Contact

- **Email**: your.email@example.com
- **LinkedIn**: linkedin.com/in/yourprofile
- **Project Issues**: GitHub Issues

---

## ğŸ™ Acknowledgments

- Yahoo Finance API for historical price data
- CoinGecko for real-time crypto metrics
- Airflow community for orchestration patterns
- dbt community for transformation best practices

---

**Built with â¤ï¸ for the crypto analytics community**
